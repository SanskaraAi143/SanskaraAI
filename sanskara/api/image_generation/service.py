import base64
import re
import logging
import os
from typing import Tuple, Optional
import google.generativeai as genai
from google.genai import types
from config import GOOGLE_API_KEY

logger = logging.getLogger(__name__)

def decode_data_uri(data_uri: str) -> Tuple[bytes, str]:
    """
    Decodes a Data URI into raw bytes and its MIME type.
    Expects format: data:<mime_type>;base64,<encoded_data>
    """
    match = re.match(r"data:(?P<mime_type>[^;]+);base64,(?P<data>.*)", data_uri)
    if not match:
        raise ValueError("Invalid Data URI format")
    
    mime_type = match.group("mime_type")
    encoded_data = match.group("data")
    decoded_bytes = base64.b64decode(encoded_data)
    return decoded_bytes, mime_type

def encode_image_to_data_uri(image_bytes: bytes, mime_type: str) -> str:
    """
    Encodes image bytes and its MIME type into a Base64 Data URI.
    """
    encoded_data = base64.b64encode(image_bytes).decode("utf-8")
    return f"data:{mime_type};base64,{encoded_data}"

async def generate_composite_image(
    venue_name: str,
    specific_area_data_uri: str,
    user_photo_data_uri: str,
    outfit_photo_data_uri: str,
    custom_instructions: Optional[str] = None
) -> Tuple[bool, Optional[str], Optional[str]]:
    """
    Generates a composite image using the Gemini Vision model.

    Args:
        venue_name: Name of the selected venue.
        specific_area_data_uri: Data URI of the venue photo.
        user_photo_data_uri: Data URI of the user's photo.
        outfit_photo_data_uri: Data URI of the outfit photo.
        custom_instructions: Optional user instructions for fitting or placement.

    Returns:
        A tuple: (success: bool, image_data_uri: Optional[str], error_message: Optional[str])
    """
    if not GOOGLE_API_KEY:
        return False, None, "Google API key not configured."

    genai.configure(api_key=GOOGLE_API_KEY)
    # Note: Model name might need adjustment, e.g., to "gemini-1.5-flash"
    model = genai.GenerativeModel("gemini-2.5-flash-image") 

    try:
        # Decode Data URIs for user, outfit, and venue photos
        user_photo_bytes, user_photo_mime_type = decode_data_uri(user_photo_data_uri)
        outfit_photo_bytes, outfit_photo_mime_type = decode_data_uri(outfit_photo_data_uri)
        venue_photo_bytes, venue_photo_mime_type = decode_data_uri(specific_area_data_uri)
        
        # --- FIX: Pass image data as dictionaries, not Blob objects ---
        user_photo_part = {"mime_type": user_photo_mime_type, "data": user_photo_bytes}
        outfit_photo_part = {"mime_type": outfit_photo_mime_type, "data": outfit_photo_bytes}
        venue_photo_part = {"mime_type": venue_photo_mime_type, "data": venue_photo_bytes}

        text_instruction = f"""Generate a photorealistic composite image. IMPORTANT: You MUST use the body, pose, facial structure, and identity of the person from the first image (user photo). You MUST only use the clothing from the second image (outfit photo); if there is a person or model in the second image, IGNORE them completely, do not use their body, face, or pose. The final background is the third image (venue photo). Place the person from the first image, wearing the outfit from the second image, into the background from the third image.
        The venue is {venue_name}.
        {f'Follow these special instructions carefully: {custom_instructions}' if custom_instructions else ''}
        """

        prompt_parts = [
            user_photo_part,
            outfit_photo_part,
            venue_photo_part,
            text_instruction
        ]

        # Use generate_content_async which returns an async iterable for streaming
        response = await model.generate_content_async(contents=prompt_parts)

        # Check for generated image in parts
        generated_image_part = None
        if response.candidates:
            for part in response.candidates[0].content.parts:
                if part.inline_data and part.inline_data.data:
                    generated_image_part = part
                    break

        if not generated_image_part:
            logger.warning("No image part found in Gemini response.")
            # Check for safety ratings or other reasons for blocked response
            error_details = "No image generated by the AI model."
            if response.prompt_feedback and response.prompt_feedback.block_reason:
                error_details += f" Reason: {response.prompt_feedback.block_reason.name}"
            return False, None, error_details

        generated_image_bytes = generated_image_part.inline_data.data
        generated_image_mime_type = generated_image_part.inline_data.mime_type

        composite_image_data_uri = encode_image_to_data_uri(generated_image_bytes, generated_image_mime_type)
        return True, composite_image_data_uri, None

    except ValueError as e:
        logger.error(f"Data URI decoding error: {e}")
        return False, None, f"Invalid image data provided: {e}"
    except Exception as e:
        logger.error(f"Gemini API or unexpected error: {e}")
        return False, None, f"Image generation failed due to API error: {e}"